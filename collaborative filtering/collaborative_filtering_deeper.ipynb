{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering\n",
    "\n",
    "We are performing collaborative filtering to see how much movies are similar to each other to give suggestions.\n",
    "\n",
    "New methods are used here:\n",
    "\n",
    "\n",
    "- ``mapValues``Pass each value in the key-value pair RDD through a map function without changing the keys\n",
    "\n",
    "- ``cache`` Persist this RDD with the default storage level\n",
    "- ``take`` Takes the first number of elements of the RDD\n",
    "- argument ``local[*]`` in setMaster method to use spark built in cluster manager and use more than one core of the pc. \n",
    "- ``saveAsTextFile`` saving the rdd as text file in the current folder. It will generate one file for each executer (core).\n",
    "\n",
    "We also see using a chain of ``map`` methods.\n",
    "\n",
    "We are going to improve upon the previous work, by using performing several steps:\n",
    "\n",
    "- throwing out movies with low rating\n",
    "- using different similarity measures\n",
    "- adding genre to the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from math import sqrt\n",
    "\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"MovieSimilarities\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading movie names...\n",
      "\n",
      "Dataset is self-joined...\n",
      "\n",
      "Duplicates are filtered...\n",
      "\n",
      "Movie data is anonymized, no userid...\n"
     ]
    }
   ],
   "source": [
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    with open(\"c:/SparkCourse/ml-100k/u.ITEM\", encoding='ascii', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            fields = line.split('|')\n",
    "            movieNames[int(fields[0])] = fields[1]\n",
    "    return movieNames\n",
    "\n",
    "#Python 3 doesn't let you pass around unpacked tuples,\n",
    "#so we explicitly extract the ratings now.\n",
    "def makePairs( userRatings ):\n",
    "    ratings = userRatings[1]\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return ((movie1, movie2), (rating1, rating2))\n",
    "\n",
    "def filterDuplicates( userRatings ): # very god for removing duplicates in spark\n",
    "    ratings = userRatings[1]\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return movie1 < movie2 # from two direction of join, keep the one that is alphabetically ahead\n",
    "#also filters movies with the same name\n",
    "\n",
    "def filterLowRatings(movieinfo):\n",
    "    rating = float(movieinfo[1][1])\n",
    "    return rating>=2  \n",
    "\n",
    "def computeCosineSimilarity(ratingPairs):\n",
    "    numPairs = 0\n",
    "    sum_xx = sum_yy = sum_xy = 0\n",
    "    for ratingX, ratingY in ratingPairs:\n",
    "        sum_xx += ratingX * ratingX\n",
    "        sum_yy += ratingY * ratingY\n",
    "        sum_xy += ratingX * ratingY\n",
    "        numPairs += 1\n",
    "\n",
    "    numerator = sum_xy\n",
    "    denominator = sqrt(sum_xx) * sqrt(sum_yy)\n",
    "\n",
    "    score = 0\n",
    "    if (denominator):\n",
    "        score = (numerator / (float(denominator)))\n",
    "\n",
    "    return (score, numPairs)\n",
    "\n",
    "\n",
    "\n",
    "def computePearsonSimilarity(ratingPairs):\n",
    "    numPairs = 0\n",
    "    sum_xx = sum_yy = sum_xy = sum_x = sum_y =  0\n",
    "    for ratingX, ratingY in ratingPairs:\n",
    "        sum_xx += ratingX * ratingX\n",
    "        sum_yy += ratingY * ratingY\n",
    "        sum_xy += ratingX * ratingY\n",
    "        sum_x += ratingX\n",
    "        sum_y += ratingY\n",
    "        numPairs += 1\n",
    "\n",
    "    numerator = sum_xy - sum_x * sum_y / numPairs\n",
    "    denominator = sqrt((sum_xx - (sum_x)**2/numPairs) * ((sum_yy - (sum_y)**2/numPairs)))\n",
    "\n",
    "    score = 0\n",
    "    if (denominator):\n",
    "        score = (numerator / (float(denominator)))\n",
    "\n",
    "    return (score, numPairs)\n",
    "\n",
    "\n",
    "print(\"\\nLoading movie names...\")\n",
    "nameDict = loadMovieNames()\n",
    "\n",
    "data = sc.textFile(\"file:///SparkCourse/ml-100k/u.data\")\n",
    "\n",
    "# Map ratings to key / value pairs: user ID => movie ID, rating\n",
    "ratings = data.map(lambda l: l.split()).map(lambda l: (int(l[0]), (int(l[1]), float(l[2])))).filter(filterLowRatings)\n",
    "\n",
    "# Emit every movie rated together by the same user.\n",
    "# Self-join to find every combination.\n",
    "joinedRatings = ratings.join(ratings)\n",
    "print(\"\\nDataset is self-joined...\")\n",
    "# At this point our RDD consists of userID => ((movieID, rating), (movieID, rating))\n",
    "\n",
    "# Filter out duplicate pairs\n",
    "uniqueJoinedRatings = joinedRatings.filter(filterDuplicates)\n",
    "print(\"\\nDuplicates are filtered...\")\n",
    "\n",
    "# Now key by (movie1, movie2) pairs.\n",
    "moviePairs = uniqueJoinedRatings.map(makePairs)\n",
    "print(\"\\nMovie data is anonymized, no userid...\")\n",
    "\n",
    "# We now have (movie1, movie2) => (rating1, rating2)\n",
    "# Now collect all ratings for each movie pair and compute similarity\n",
    "moviePairRatings = moviePairs.groupByKey()\n",
    "\n",
    "# We now have (movie1, movie2) = > (rating1, rating2), (rating1, rating2) ...\n",
    "# Can now compute similarities.\n",
    "moviePairSimilarities = moviePairRatings.mapValues(computePearsonSimilarity).cache()\n",
    "\n",
    "# Save the results if desired\n",
    "#moviePairSimilarities.sortByKey()\n",
    "#moviePairSimilarities.saveAsTextFile(\"movie-sims\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar movies for Casablanca (1942)\n",
      "Third Man, The (1949)\tscore: 0.6036773350335661\tstrength: 52\n",
      "Maltese Falcon, The (1941)\tscore: 0.5029606006150984\tstrength: 111\n",
      "Shine (1996)\tscore: 0.4770054774358142\tstrength: 68\n",
      "Bob Roberts (1992)\tscore: 0.473589560952675\tstrength: 57\n",
      "It Happened One Night (1934)\tscore: 0.4577801353022157\tstrength: 60\n",
      "African Queen, The (1951)\tscore: 0.4469809047597789\tstrength: 113\n",
      "My Left Foot (1989)\tscore: 0.42873131674438764\tstrength: 67\n",
      "Chinatown (1974)\tscore: 0.4236842501725612\tstrength: 105\n",
      "Roman Holiday (1953)\tscore: 0.4121908459625984\tstrength: 51\n",
      "Manchurian Candidate, The (1962)\tscore: 0.41196637795707625\tstrength: 90\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract similarities for the movie we care about that are \"good\".\n",
    "scoreThreshold = 0.38\n",
    "coOccurenceThreshold = 50\n",
    "\n",
    "movieID = 483 # Casablanca\n",
    "\n",
    "# Filter for movies with this sim that are \"good\" as defined by\n",
    "# our quality thresholds above (filtering all at the same time)\n",
    "filteredResults = moviePairSimilarities.filter(lambda pairSim: \\\n",
    "    (pairSim[0][0] == movieID or pairSim[0][1] == movieID) \\\n",
    "    and pairSim[1][0] > scoreThreshold and pairSim[1][1] > coOccurenceThreshold)\n",
    "\n",
    "# Sort by quality score.\n",
    "results = filteredResults.map(lambda pairSim: (pairSim[1], pairSim[0])).sortByKey(ascending = False).take(10)\n",
    "\n",
    "print(\"Top 10 similar movies for \" + nameDict[movieID])\n",
    "for result in results:\n",
    "    (sim, pair) = result\n",
    "    # Display the similarity result that isn't the movie we're looking at\n",
    "    similarMovieID = pair[0]\n",
    "    if (similarMovieID == movieID):\n",
    "        similarMovieID = pair[1]\n",
    "    print(nameDict[similarMovieID] + \"\\tscore: \" + str(sim[0]) + \"\\tstrength: \" + str(sim[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based the cosine score, here is the results:\n",
    "\n",
    "Top 10 similar movies for Casablanca (1942)\n",
    "- Third Man, The (1949)\tscore: 0.9914873737018578\tstrength: 52\n",
    "- Maltese Falcon, The (1941)\tscore: 0.9884013076509861\tstrength: 111\n",
    "- African Queen, The (1951)\tscore: 0.9865259305014779\tstrength: 113\n",
    "- Manchurian Candidate, The (1962)\tscore: 0.984613301863293\tstrength: 90\n",
    "- It Happened One Night (1934)\tscore: 0.9845081807112164\tstrength: 60\n",
    "- Vertigo (1958)\tscore: 0.9832931334707176\tstrength: 127\n",
    "- Citizen Kane (1941)\tscore: 0.9830936340463006\tstrength: 143\n",
    "- Silence of the Lambs, The (1991)\tscore: 0.9829257762211996\tstrength: 185\n",
    "- Treasure of the Sierra Madre, The (1948)\tscore: 0.9828749443758958\tstrength: 61\n",
    "- Dial M for Murder (1954)\tscore: 0.9828585785349522\tstrength: 59\n",
    "\n",
    "Personally, I find the results from the pearson correlation is more related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
