{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering\n",
    "\n",
    "We are performing collaborative filtering to see how much movies are similar to each other to give suggestions.\n",
    "\n",
    "New methods are used here:\n",
    "\n",
    "\n",
    "- ``mapValues``Pass each value in the key-value pair RDD through a map function without changing the keys\n",
    "\n",
    "- ``cache`` Persist this RDD with the default storage level\n",
    "- ``take`` Takes the first number of elements of the RDD\n",
    "- argument ``local[*]`` in setMaster method to use spark built in cluster manager and use more than one core of the pc. \n",
    "- ``saveAsTextFile`` saving the rdd as text file in the current folder. It will generate one file for each executer (core).\n",
    "\n",
    "We also see using a chain of ``map`` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from math import sqrt\n",
    "\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"MovieSimilarities\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading movie names...\n",
      "\n",
      "Dataset is self-joined...\n",
      "\n",
      "Duplicates are filtered...\n",
      "\n",
      "Movie data is anonymized, no userid...\n"
     ]
    }
   ],
   "source": [
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    with open(\"c:/SparkCourse/ml-100k/u.ITEM\", encoding='ascii', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            fields = line.split('|')\n",
    "            movieNames[int(fields[0])] = fields[1]\n",
    "    return movieNames\n",
    "\n",
    "#Python 3 doesn't let you pass around unpacked tuples,\n",
    "#so we explicitly extract the ratings now.\n",
    "def makePairs( userRatings ):\n",
    "    ratings = userRatings[1]\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return ((movie1, movie2), (rating1, rating2))\n",
    "\n",
    "def filterDuplicates( userRatings ): # very god for removing duplicates in spark\n",
    "    ratings = userRatings[1]\n",
    "    (movie1, rating1) = ratings[0]\n",
    "    (movie2, rating2) = ratings[1]\n",
    "    return movie1 < movie2 # from two direction of join, keep the one that is alphabetically ahead\n",
    "#also filters movies with the same name\n",
    "\n",
    "\n",
    "def computeCosineSimilarity(ratingPairs):\n",
    "    numPairs = 0\n",
    "    sum_xx = sum_yy = sum_xy = 0\n",
    "    for ratingX, ratingY in ratingPairs:\n",
    "        sum_xx += ratingX * ratingX\n",
    "        sum_yy += ratingY * ratingY\n",
    "        sum_xy += ratingX * ratingY\n",
    "        numPairs += 1\n",
    "\n",
    "    numerator = sum_xy\n",
    "    denominator = sqrt(sum_xx) * sqrt(sum_yy)\n",
    "\n",
    "    score = 0\n",
    "    if (denominator):\n",
    "        score = (numerator / (float(denominator)))\n",
    "\n",
    "    return (score, numPairs)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nLoading movie names...\")\n",
    "nameDict = loadMovieNames()\n",
    "\n",
    "data = sc.textFile(\"file:///SparkCourse/ml-100k/u.data\")\n",
    "\n",
    "# Map ratings to key / value pairs: user ID => movie ID, rating\n",
    "ratings = data.map(lambda l: l.split()).map(lambda l: (int(l[0]), (int(l[1]), float(l[2]))))\n",
    "\n",
    "# Emit every movie rated together by the same user.\n",
    "# Self-join to find every combination.\n",
    "joinedRatings = ratings.join(ratings)\n",
    "print(\"\\nDataset is self-joined...\")\n",
    "# At this point our RDD consists of userID => ((movieID, rating), (movieID, rating))\n",
    "\n",
    "# Filter out duplicate pairs\n",
    "uniqueJoinedRatings = joinedRatings.filter(filterDuplicates)\n",
    "print(\"\\nDuplicates are filtered...\")\n",
    "\n",
    "# Now key by (movie1, movie2) pairs.\n",
    "moviePairs = uniqueJoinedRatings.map(makePairs)\n",
    "print(\"\\nMovie data is anonymized, no userid...\")\n",
    "\n",
    "# We now have (movie1, movie2) => (rating1, rating2)\n",
    "# Now collect all ratings for each movie pair and compute similarity\n",
    "moviePairRatings = moviePairs.groupByKey()\n",
    "\n",
    "# We now have (movie1, movie2) = > (rating1, rating2), (rating1, rating2) ...\n",
    "# Can now compute similarities.\n",
    "moviePairSimilarities = moviePairRatings.mapValues(computeCosineSimilarity).cache()\n",
    "\n",
    "# Save the results if desired\n",
    "#moviePairSimilarities.sortByKey()\n",
    "#moviePairSimilarities.saveAsTextFile(\"movie-sims\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 similar movies for 12 Angry Men (1957)\n",
      "Casablanca (1942)\tscore: 0.9814271702667515\tstrength: 75\n",
      "Sting, The (1973)\tscore: 0.9800565289675167\tstrength: 78\n",
      "Amadeus (1984)\tscore: 0.9779135349052294\tstrength: 88\n",
      "One Flew Over the Cuckoo's Nest (1975)\tscore: 0.9778218847859345\tstrength: 81\n",
      "Star Wars (1977)\tscore: 0.9776576120448436\tstrength: 109\n",
      "Schindler's List (1993)\tscore: 0.977620731722541\tstrength: 80\n",
      "Silence of the Lambs, The (1991)\tscore: 0.9774123548400772\tstrength: 97\n",
      "Psycho (1960)\tscore: 0.9772611576478752\tstrength: 75\n",
      "Shawshank Redemption, The (1994)\tscore: 0.9757950238470389\tstrength: 84\n",
      "Citizen Kane (1941)\tscore: 0.9756537106878723\tstrength: 71\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract similarities for the movie we care about that are \"good\".\n",
    "scoreThreshold = 0.975\n",
    "coOccurenceThreshold = 70\n",
    "\n",
    "movieID = 178 # 12 Angry Men\n",
    "\n",
    "# Filter for movies with this sim that are \"good\" as defined by\n",
    "# our quality thresholds above (filtering all at the same time)\n",
    "filteredResults = moviePairSimilarities.filter(lambda pairSim: \\\n",
    "    (pairSim[0][0] == movieID or pairSim[0][1] == movieID) \\\n",
    "    and pairSim[1][0] > scoreThreshold and pairSim[1][1] > coOccurenceThreshold)\n",
    "\n",
    "# Sort by quality score.\n",
    "results = filteredResults.map(lambda pairSim: (pairSim[1], pairSim[0])).sortByKey(ascending = False).take(10)\n",
    "\n",
    "print(\"Top 10 similar movies for \" + nameDict[movieID])\n",
    "for result in results:\n",
    "    (sim, pair) = result\n",
    "    # Display the similarity result that isn't the movie we're looking at\n",
    "    similarMovieID = pair[0]\n",
    "    if (similarMovieID == movieID):\n",
    "        similarMovieID = pair[1]\n",
    "    print(nameDict[similarMovieID] + \"\\tscore: \" + str(sim[0]) + \"\\tstrength: \" + str(sim[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
